{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HRP vs HERC\n\nIn this tutorial we will compare the\n:class:`~skfolio.optimization.HierarchicalRiskParity` (HRP) vs the\n:class:`~skfolio.optimization.HierarchicalEqualRiskContribution` (HERC) optimization.\n\nFor that comparison we consider a 3 months rolling (60 business days) allocation fitted\non the preceding year of data (255 business days) that minimizes the CVaR.\n\nWe will use `GridSearchCV` to select the optimal parameters of each model on the\ntraining set using cross-validation that achieve the highest average out-of-sample\nMean-CVaR ratio.\n\nThen, we will evaluate the models on the test set and compare it with the equal-weighted\nbenchmark.\n\nFinally, we will use the :class:`~skfolio.model_selection.CombinatorialPurgedCV` to\nanalyse the stability and distribution of both models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\nWe load the FTSE 100 `dataset <datasets>` composed of the daily prices of 64\nassets from the FTSE 100 Index composition starting from 2000-01-04 up to 2023-05-31:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from plotly.io import show\nfrom sklearn.model_selection import GridSearchCV, train_test_split\n\nfrom skfolio import Population, RatioMeasure, RiskMeasure\nfrom skfolio.cluster import HierarchicalClustering, LinkageMethod\nfrom skfolio.datasets import load_ftse100_dataset\nfrom skfolio.distance import KendallDistance, PearsonDistance\nfrom skfolio.metrics import make_scorer\nfrom skfolio.model_selection import (\n    CombinatorialPurgedCV,\n    WalkForward,\n    cross_val_predict,\n)\nfrom skfolio.optimization import (\n    EqualWeighted,\n    HierarchicalEqualRiskContribution,\n    HierarchicalRiskParity,\n)\nfrom skfolio.preprocessing import prices_to_returns\n\nprices = load_ftse100_dataset()\n\nX = prices_to_returns(prices)\nX_train, X_test = train_test_split(X, test_size=0.33, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model\nWe create two models: an HRP-CVaR and an HERC-CVaR:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_hrp = HierarchicalRiskParity(\n    risk_measure=RiskMeasure.CVAR,\n    hierarchical_clustering_estimator=HierarchicalClustering(),\n)\n\nmodel_herc = HierarchicalEqualRiskContribution(\n    risk_measure=RiskMeasure.CVAR,\n    hierarchical_clustering_estimator=HierarchicalClustering(),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter Tuning\nFor HRP and HERC, we find the model parameters that maximizes the average\nout-of-sample Mean-CVaR ratio using `GridSearchCV` with `WalkForward` cross-validation\non the training set. The `WalkForward` are chosen to simulate a three months\n(60 business days) rolling portfolio fitted on the previous year (255 business days):\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = WalkForward(train_size=255, test_size=60)\n\ngrid_search_hrp = GridSearchCV(\n    estimator=model_hrp,\n    cv=cv,\n    n_jobs=-1,\n    param_grid={\n        \"distance_estimator\": [PearsonDistance(), KendallDistance()],\n        \"hierarchical_clustering_estimator__linkage_method\": [\n            # LinkageMethod.SINGLE,\n            LinkageMethod.WARD,\n            LinkageMethod.COMPLETE,\n        ],\n    },\n    scoring=make_scorer(RatioMeasure.CVAR_RATIO),\n)\ngrid_search_hrp.fit(X_train)\nmodel_hrp = grid_search_hrp.best_estimator_\nprint(model_hrp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grid_search_herc = grid_search_hrp.set_params(estimator=model_herc)\ngrid_search_herc.fit(X_train)\nmodel_herc = grid_search_herc.best_estimator_\nprint(model_herc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction\nWe evaluate the two models using the same `WalkForward` object on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_hrp = cross_val_predict(\n    model_hrp,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(name=\"HRP\"),\n)\n\npred_herc = cross_val_predict(\n    model_herc,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(name=\"HERC\"),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each predicted object is a `MultiPeriodPortfolio`.\nFor improved analysis, we can add them to a `Population`:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population = Population([pred_hrp, pred_herc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the rolling portfolios compositions:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_composition(display_sub_ptf_name=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the rolling portfolios cumulative returns on the test set:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_cumulative_returns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis\nHERC outperform HRP both in terms of CVaR minimization and Mean-CVaR ratio\nmaximization:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ptf in population:\n    print(\"=\" * 25)\n    print(\" \" * 8 + ptf.name)\n    print(\"=\" * 25)\n    print(f\"CVaR : {ptf.cvar:0.2%}\")\n    print(f\"Mean-CVaR ratio : {ptf.cvar_ratio:0.4f}\")\n    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combinatorial Purged Cross-Validation\nOnly using one testing path (the historical path) may not be enough to compare\nmodels. For a more robust analysis, we can use the\n:class:`~skfolio.model_selection.CombinatorialPurgedCV` to create multiple testing\npaths from different training folds combinations:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv = CombinatorialPurgedCV(n_folds=16, n_test_folds=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose `n_folds` and `n_test_folds` to get more than 100 test paths and an average\ntraining size around 255 days:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv.summary(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pred_hrp = cross_val_predict(\n    model_hrp,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(tag=\"HRP\"),\n)\npred_herc = cross_val_predict(\n    model_herc,\n    X_test,\n    cv=cv,\n    n_jobs=-1,\n    portfolio_params=dict(tag=\"HERC\"),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The predicted object is a `Population` of `MultiPeriodPortfolio`. Each\n`MultiPeriodPortfolio` represents one testing path of a rolling portfolio.\nFor improved analysis, we can merge the populations of each model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population = pred_hrp + pred_herc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Distribution\nWe plot the out-of-sample distribution of Mean-CVaR ratio for each model:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "population.plot_distribution(\n    measure_list=[RatioMeasure.CVAR_RATIO], tag_list=[\"HRP\", \"HERC\"], n_bins=50\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for pred in [pred_hrp, pred_herc]:\n    print(\"=\" * 25)\n    print(\" \" * 8 + pred[0].tag)\n    print(\"=\" * 25)\n    print(\n        \"Average Mean-CVaR ratio :\"\n        f\" {pred.measures_mean(measure=RatioMeasure.CVAR_RATIO):0.4f}\"\n    )\n    print(\n        \"Std Mean-CVaR ratio :\"\n        f\" {pred.measures_std(measure=RatioMeasure.CVAR_RATIO):0.4f}\"\n    )\n    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that, in terms of Mean-CVaR ratio distribution, the HERC model has a higher\nmean than the HRP model but also a higher standard deviation. In other words, HERC is\nless stable than HRP but performs slightly better in average.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can do the same analysis for other measures:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = population.plot_distribution(\n    measure_list=[\n        RatioMeasure.ANNUALIZED_SHARPE_RATIO,\n        RatioMeasure.ANNUALIZED_SORTINO_RATIO,\n    ],\n    tag_list=[\"HRP\", \"HERC\"],\n    n_bins=50,\n)\nshow(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}